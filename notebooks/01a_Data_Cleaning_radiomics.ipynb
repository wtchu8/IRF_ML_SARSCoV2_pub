{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformat and reorganize the radiomics data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumed data organization:\n",
    "- $PATH/\n",
    "    - raw/ (contains input data files)\n",
    "    - tables/ (contains output data files)\n",
    "    - figures/ (contains output image files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External packages\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import yaml\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local packages\n",
    "sys.path.append('../src')\n",
    "from ninetynine import ninetynine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Study Day</th>\n",
       "      <th>Study Date</th>\n",
       "      <th>File Name</th>\n",
       "      <th>Class</th>\n",
       "      <th>VoxelVolume</th>\n",
       "      <th>Maximum3DDiameter</th>\n",
       "      <th>Compactness2</th>\n",
       "      <th>MeshVolume</th>\n",
       "      <th>...</th>\n",
       "      <th>HighGrayLevelZoneEmphasis</th>\n",
       "      <th>SmallAreaEmphasis</th>\n",
       "      <th>LowGrayLevelZoneEmphasis</th>\n",
       "      <th>ZoneEntropy</th>\n",
       "      <th>SmallAreaLowGrayLevelEmphasis</th>\n",
       "      <th>Coarseness</th>\n",
       "      <th>Complexity</th>\n",
       "      <th>Strength</th>\n",
       "      <th>Contrast.1</th>\n",
       "      <th>Busyness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64-01</td>\n",
       "      <td>B03757</td>\n",
       "      <td>-6</td>\n",
       "      <td>2020/03/16</td>\n",
       "      <td>B03757_20200316</td>\n",
       "      <td>Infected</td>\n",
       "      <td>214687.6968</td>\n",
       "      <td>117.993344</td>\n",
       "      <td>0.063035</td>\n",
       "      <td>214813.9478</td>\n",
       "      <td>...</td>\n",
       "      <td>263.840627</td>\n",
       "      <td>0.703526</td>\n",
       "      <td>0.026156</td>\n",
       "      <td>6.520020</td>\n",
       "      <td>0.016590</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2050.728222</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>0.045985</td>\n",
       "      <td>1200.810742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64-01</td>\n",
       "      <td>B03757</td>\n",
       "      <td>2</td>\n",
       "      <td>2020/03/24</td>\n",
       "      <td>B03757_20200324</td>\n",
       "      <td>Infected</td>\n",
       "      <td>166787.9929</td>\n",
       "      <td>106.848905</td>\n",
       "      <td>0.062049</td>\n",
       "      <td>166806.4319</td>\n",
       "      <td>...</td>\n",
       "      <td>398.640737</td>\n",
       "      <td>0.666246</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>6.784057</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2100.919283</td>\n",
       "      <td>0.024958</td>\n",
       "      <td>0.032996</td>\n",
       "      <td>235.133257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64-01</td>\n",
       "      <td>B03757</td>\n",
       "      <td>4</td>\n",
       "      <td>2020/03/26</td>\n",
       "      <td>B03757_20200326</td>\n",
       "      <td>Infected</td>\n",
       "      <td>179172.8874</td>\n",
       "      <td>110.873560</td>\n",
       "      <td>0.070562</td>\n",
       "      <td>179211.0040</td>\n",
       "      <td>...</td>\n",
       "      <td>390.598883</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>6.857994</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1626.651312</td>\n",
       "      <td>0.017752</td>\n",
       "      <td>0.049790</td>\n",
       "      <td>343.480410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64-01</td>\n",
       "      <td>B03757</td>\n",
       "      <td>6</td>\n",
       "      <td>2020/03/28</td>\n",
       "      <td>B03757_20200328</td>\n",
       "      <td>Infected</td>\n",
       "      <td>183788.8962</td>\n",
       "      <td>114.183678</td>\n",
       "      <td>0.068394</td>\n",
       "      <td>183864.0813</td>\n",
       "      <td>...</td>\n",
       "      <td>391.586046</td>\n",
       "      <td>0.662147</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>6.857685</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1695.859842</td>\n",
       "      <td>0.018573</td>\n",
       "      <td>0.046353</td>\n",
       "      <td>343.089081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64-01</td>\n",
       "      <td>B03757</td>\n",
       "      <td>8</td>\n",
       "      <td>2020/03/30</td>\n",
       "      <td>B03757_20200330</td>\n",
       "      <td>Infected</td>\n",
       "      <td>192435.5003</td>\n",
       "      <td>112.927602</td>\n",
       "      <td>0.069981</td>\n",
       "      <td>192447.8780</td>\n",
       "      <td>...</td>\n",
       "      <td>365.438565</td>\n",
       "      <td>0.667409</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>6.730401</td>\n",
       "      <td>0.003621</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1063.986963</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.041377</td>\n",
       "      <td>429.421847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Study Subject Study Day  Study Date        File Name     Class  \\\n",
       "0  64-01  B03757        -6  2020/03/16  B03757_20200316  Infected   \n",
       "1  64-01  B03757         2  2020/03/24  B03757_20200324  Infected   \n",
       "2  64-01  B03757         4  2020/03/26  B03757_20200326  Infected   \n",
       "3  64-01  B03757         6  2020/03/28  B03757_20200328  Infected   \n",
       "4  64-01  B03757         8  2020/03/30  B03757_20200330  Infected   \n",
       "\n",
       "   VoxelVolume  Maximum3DDiameter  Compactness2   MeshVolume  ...  \\\n",
       "0  214687.6968         117.993344      0.063035  214813.9478  ...   \n",
       "1  166787.9929         106.848905      0.062049  166806.4319  ...   \n",
       "2  179172.8874         110.873560      0.070562  179211.0040  ...   \n",
       "3  183788.8962         114.183678      0.068394  183864.0813  ...   \n",
       "4  192435.5003         112.927602      0.069981  192447.8780  ...   \n",
       "\n",
       "   HighGrayLevelZoneEmphasis  SmallAreaEmphasis  LowGrayLevelZoneEmphasis  \\\n",
       "0                 263.840627           0.703526                  0.026156   \n",
       "1                 398.640737           0.666246                  0.005352   \n",
       "2                 390.598883           0.665000                  0.006050   \n",
       "3                 391.586046           0.662147                  0.006006   \n",
       "4                 365.438565           0.667409                  0.006288   \n",
       "\n",
       "   ZoneEntropy  SmallAreaLowGrayLevelEmphasis  Coarseness   Complexity  \\\n",
       "0     6.520020                       0.016590    0.000002  2050.728222   \n",
       "1     6.784057                       0.003114    0.000006  2100.919283   \n",
       "2     6.857994                       0.003507    0.000005  1626.651312   \n",
       "3     6.857685                       0.003464    0.000005  1695.859842   \n",
       "4     6.730401                       0.003621    0.000005  1063.986963   \n",
       "\n",
       "   Strength  Contrast.1     Busyness  \n",
       "0  0.006714    0.045985  1200.810742  \n",
       "1  0.024958    0.032996   235.133257  \n",
       "2  0.017752    0.049790   343.480410  \n",
       "3  0.018573    0.046353   343.089081  \n",
       "4  0.009600    0.041377   429.421847  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "with open('../config/paths.yaml','r') as file:\n",
    "    paths_list = yaml.safe_load(file)\n",
    "    PATH = os.path.abspath(paths_list['PATH'])\n",
    "\n",
    "data = pd.read_csv(os.path.join(PATH,'raw','DL-Lung-Features-SARS-CoV-2-NHP-064-1-2-3_complete.csv'))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of space in column names, annoying to deal with later\n",
    "data = data.rename(columns={'Study Day':'StudyDay'})\n",
    "data = data.rename(columns={'Study Date':'StudyDate'})\n",
    "\n",
    "# Get lists of the id columns and the dependent variable columns\n",
    "id_cols=['Study','Subject','StudyDay','StudyDate','File Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##need to adjust lists with the .1 and .2 notation\n",
    "shape_list=['VoxelVolume','Maximum3DDiameter','Compactness2','MeshVolume'\n",
    ",'MajorAxisLength','Sphericity','LeastAxisLength','Elongation'\n",
    ",'Compactness1','SurfaceVolumeRatio','Maximum2DDiameterSlice'\n",
    ",'Flatness','SurfaceArea','MinorAxisLength'\n",
    ",'Maximum2DDiameterColumn','SphericalDisproportion','Maximum2DDiameterRow']\n",
    "\n",
    "glcm_list=['JointAverage','Autocorrelation','JointEntropy','ClusterShade',\n",
    "'MaximumProbability','Idmn','JointEnergy','Contrast',\n",
    "'DifferenceEntropy','InverseVariance','DifferenceVariance',\n",
    "'Idn','Idm','Correlation','SumAverage',\n",
    "'SumEntropy','MCC','SumSquares','ClusterProminence',\n",
    "'Imc2','Imc1','DifferenceAverage','Id','ClusterTendency']\n",
    "\n",
    "gldm_list=['GrayLevelVariance','HighGrayLevelEmphasis'\n",
    ",'DependenceEntropy','DependenceNonUniformity'\n",
    ",'GrayLevelNonUniformity','SmallDependenceEmphasis'\n",
    ",'SmallDependenceHighGrayLevelEmphasis','DependenceNonUniformityNormalized'\n",
    ",'LargeDependenceEmphasis','LargeDependenceLowGrayLevelEmphasis'\n",
    ",'DependenceVariance','LargeDependenceHighGrayLevelEmphasis'\n",
    ",'SmallDependenceLowGrayLevelEmphasis','LowGrayLevelEmphasis']\n",
    "\n",
    "firstorder_list=['InterquartileRange','Skewness'\n",
    ",'Uniformity','Median','Energy'\n",
    ",'RobustMeanAbsoluteDeviation','MeanAbsoluteDeviation'\n",
    ",'StandardDeviation','TotalEnergy'\n",
    ",'RootMeanSquared','90Percentile'\n",
    ",'Minimum','Entropy','Range'\n",
    ",'Variance','10Percentile','Kurtosis'\n",
    ",'Maximum','Mean']\n",
    "\n",
    "glrlm_list=['ShortRunLowGrayLevelEmphasis','GrayLevelVariance.1'\n",
    ",'LowGrayLevelRunEmphasis','GrayLevelNonUniformityNormalized'\n",
    ",'RunVariance','GrayLevelNonUniformity.1'\n",
    ",'LongRunEmphasis','ShortRunHighGrayLevelEmphasis'\n",
    ",'RunLengthNonUniformity','ShortRunEmphasis'\n",
    ",'LongRunHighGrayLevelEmphasis','RunPercentage'\n",
    ",'LongRunLowGrayLevelEmphasis','RunEntropy'\n",
    ",'HighGrayLevelRunEmphasis','RunLengthNonUniformityNormalized']\n",
    "\n",
    "glszm_list=['GrayLevelVariance.2','ZoneVariance'\n",
    ",'GrayLevelNonUniformityNormalized.1','SizeZoneNonUniformityNormalized'\n",
    ",'SizeZoneNonUniformity','GrayLevelNonUniformity.2'\n",
    ",'LargeAreaEmphasis','SmallAreaHighGrayLevelEmphasis'\n",
    ",'ZonePercentage','LargeAreaLowGrayLevelEmphasis'\n",
    ",'LargeAreaHighGrayLevelEmphasis','HighGrayLevelZoneEmphasis'\n",
    ",'SmallAreaEmphasis','LowGrayLevelZoneEmphasis'\n",
    ",'ZoneEntropy','SmallAreaLowGrayLevelEmphasis']\n",
    "\n",
    "ngtdm_list=['Coarseness','Complexity','Strength'\n",
    ",'Contrast.1','Busyness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FALSE: I've got 99 problems, but repeat features in grouping lists is not one\n"
     ]
    }
   ],
   "source": [
    "# Confirm there aren't any repeats\n",
    "rep_bool = len(set(shape_list+glcm_list+gldm_list+firstorder_list+glrlm_list+glszm_list+ngtdm_list)) != len(shape_list+glcm_list+gldm_list+firstorder_list+glrlm_list+glszm_list+ngtdm_list)\n",
    "ninetynine(rep_bool,'repeat features in grouping lists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column not in list: Study\n",
      "Column not in list: Subject\n",
      "Column not in list: StudyDay\n",
      "Column not in list: StudyDate\n",
      "Column not in list: File Name\n",
      "Column not in list: Class\n"
     ]
    }
   ],
   "source": [
    "# Rename radiomic features to include class\n",
    "for name in data.columns:\n",
    "    if name in shape_list:\n",
    "        data.rename(columns={name:name.split('.')[0]+'-shape'},inplace=True)\n",
    "    elif name in glcm_list:\n",
    "        data.rename(columns={name:name.split('.')[0]+'-glcm'},inplace=True)\n",
    "    elif name in gldm_list:\n",
    "        data.rename(columns={name:name.split('.')[0]+'-gldm'},inplace=True)\n",
    "    elif name in firstorder_list:\n",
    "        data.rename(columns={name:name.split('.')[0]+'-firstorder'},inplace=True)\n",
    "    elif name in glrlm_list:\n",
    "        data.rename(columns={name:name.split('.')[0]+'-glrlm'},inplace=True)\n",
    "    elif name in glszm_list:\n",
    "        data.rename(columns={name:name.split('.')[0]+'-glszm'},inplace=True)\n",
    "    elif name in ngtdm_list:\n",
    "        data.rename(columns={name:name.split('.')[0]+'-ngtdm'},inplace=True)\n",
    "    else:\n",
    "        print('Column not in list:',name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature name list for storage\n",
    "var_cols=data.drop(id_cols+['Class'],axis=1).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Study\n",
      "2) Subject\n",
      "3) StudyDay\n",
      "4) StudyDate\n",
      "5) File Name\n",
      "6) Class\n",
      "7) VoxelVolume-shape\n",
      "8) Maximum3DDiameter-shape\n",
      "9) Compactness2-shape\n",
      "10) MeshVolume-shape\n",
      "11) MajorAxisLength-shape\n",
      "12) Sphericity-shape\n",
      "13) LeastAxisLength-shape\n",
      "14) Elongation-shape\n",
      "15) Compactness1-shape\n",
      "16) SurfaceVolumeRatio-shape\n",
      "17) Maximum2DDiameterSlice-shape\n",
      "18) Flatness-shape\n",
      "19) SurfaceArea-shape\n",
      "20) MinorAxisLength-shape\n",
      "21) Maximum2DDiameterColumn-shape\n",
      "22) SphericalDisproportion-shape\n",
      "23) Maximum2DDiameterRow-shape\n",
      "24) JointAverage-glcm\n",
      "25) Autocorrelation-glcm\n",
      "26) JointEntropy-glcm\n",
      "27) ClusterShade-glcm\n",
      "28) MaximumProbability-glcm\n",
      "29) Idmn-glcm\n",
      "30) JointEnergy-glcm\n",
      "31) Contrast-glcm\n",
      "32) DifferenceEntropy-glcm\n",
      "33) InverseVariance-glcm\n",
      "34) DifferenceVariance-glcm\n",
      "35) Idn-glcm\n",
      "36) Idm-glcm\n",
      "37) Correlation-glcm\n",
      "38) SumAverage-glcm\n",
      "39) SumEntropy-glcm\n",
      "40) MCC-glcm\n",
      "41) SumSquares-glcm\n",
      "42) ClusterProminence-glcm\n",
      "43) Imc2-glcm\n",
      "44) Imc1-glcm\n",
      "45) DifferenceAverage-glcm\n",
      "46) Id-glcm\n",
      "47) ClusterTendency-glcm\n",
      "48) GrayLevelVariance-gldm\n",
      "49) HighGrayLevelEmphasis-gldm\n",
      "50) DependenceEntropy-gldm\n",
      "51) DependenceNonUniformity-gldm\n",
      "52) GrayLevelNonUniformity-gldm\n",
      "53) SmallDependenceEmphasis-gldm\n",
      "54) SmallDependenceHighGrayLevelEmphasis-gldm\n",
      "55) DependenceNonUniformityNormalized-gldm\n",
      "56) LargeDependenceEmphasis-gldm\n",
      "57) LargeDependenceLowGrayLevelEmphasis-gldm\n",
      "58) DependenceVariance-gldm\n",
      "59) LargeDependenceHighGrayLevelEmphasis-gldm\n",
      "60) SmallDependenceLowGrayLevelEmphasis-gldm\n",
      "61) LowGrayLevelEmphasis-gldm\n",
      "62) InterquartileRange-firstorder\n",
      "63) Skewness-firstorder\n",
      "64) Uniformity-firstorder\n",
      "65) Median-firstorder\n",
      "66) Energy-firstorder\n",
      "67) RobustMeanAbsoluteDeviation-firstorder\n",
      "68) MeanAbsoluteDeviation-firstorder\n",
      "69) StandardDeviation-firstorder\n",
      "70) TotalEnergy-firstorder\n",
      "71) RootMeanSquared-firstorder\n",
      "72) 90Percentile-firstorder\n",
      "73) Minimum-firstorder\n",
      "74) Entropy-firstorder\n",
      "75) Range-firstorder\n",
      "76) Variance-firstorder\n",
      "77) 10Percentile-firstorder\n",
      "78) Kurtosis-firstorder\n",
      "79) Maximum-firstorder\n",
      "80) Mean-firstorder\n",
      "81) ShortRunLowGrayLevelEmphasis-glrlm\n",
      "82) GrayLevelVariance-glrlm\n",
      "83) LowGrayLevelRunEmphasis-glrlm\n",
      "84) GrayLevelNonUniformityNormalized-glrlm\n",
      "85) RunVariance-glrlm\n",
      "86) GrayLevelNonUniformity-glrlm\n",
      "87) LongRunEmphasis-glrlm\n",
      "88) ShortRunHighGrayLevelEmphasis-glrlm\n",
      "89) RunLengthNonUniformity-glrlm\n",
      "90) ShortRunEmphasis-glrlm\n",
      "91) LongRunHighGrayLevelEmphasis-glrlm\n",
      "92) RunPercentage-glrlm\n",
      "93) LongRunLowGrayLevelEmphasis-glrlm\n",
      "94) RunEntropy-glrlm\n",
      "95) HighGrayLevelRunEmphasis-glrlm\n",
      "96) RunLengthNonUniformityNormalized-glrlm\n",
      "97) GrayLevelVariance-glszm\n",
      "98) ZoneVariance-glszm\n",
      "99) GrayLevelNonUniformityNormalized-glszm\n",
      "100) SizeZoneNonUniformityNormalized-glszm\n",
      "101) SizeZoneNonUniformity-glszm\n",
      "102) GrayLevelNonUniformity-glszm\n",
      "103) LargeAreaEmphasis-glszm\n",
      "104) SmallAreaHighGrayLevelEmphasis-glszm\n",
      "105) ZonePercentage-glszm\n",
      "106) LargeAreaLowGrayLevelEmphasis-glszm\n",
      "107) LargeAreaHighGrayLevelEmphasis-glszm\n",
      "108) HighGrayLevelZoneEmphasis-glszm\n",
      "109) SmallAreaEmphasis-glszm\n",
      "110) LowGrayLevelZoneEmphasis-glszm\n",
      "111) ZoneEntropy-glszm\n",
      "112) SmallAreaLowGrayLevelEmphasis-glszm\n",
      "113) Coarseness-ngtdm\n",
      "114) Complexity-ngtdm\n",
      "115) Strength-ngtdm\n",
      "116) Contrast-ngtdm\n",
      "117) Busyness-ngtdm\n"
     ]
    }
   ],
   "source": [
    "# Print column names\n",
    "i=0\n",
    "for name in data.columns:\n",
    "    i += 1\n",
    "    print (str(i)+') '+str(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop entries with errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove a specific set of entries that have erroneous StudyDay values\n",
    "data.loc[(data.Subject == 'B03942') & (data.StudyDate < '2020/06/01')] = None\n",
    "data.dropna(how='all',inplace=True)\n",
    "# Fix specific errors in group coding\n",
    "data.loc[data.Subject == 'B03942','Class'] = 'Mock'\n",
    "data.loc[data.Subject == 'G57L','Class'] = 'Mock' \n",
    "data.loc[data.Subject == 'G57N','Class'] = 'Infected' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>File Name</th>\n",
       "      <th>StudyDay</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>B03942</td>\n",
       "      <td>B03041_20200609</td>\n",
       "      <td>-7</td>\n",
       "      <td>Mock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>B03942</td>\n",
       "      <td>B03971_20200618</td>\n",
       "      <td>2</td>\n",
       "      <td>Mock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>B03942</td>\n",
       "      <td>B03941_20200620</td>\n",
       "      <td>4</td>\n",
       "      <td>Mock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>B03942</td>\n",
       "      <td>B03961_20200622</td>\n",
       "      <td>6</td>\n",
       "      <td>Mock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>B03942</td>\n",
       "      <td>B03911_20200624</td>\n",
       "      <td>8</td>\n",
       "      <td>Mock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject        File Name StudyDay Class\n",
       "84  B03942  B03041_20200609       -7  Mock\n",
       "85  B03942  B03971_20200618        2  Mock\n",
       "86  B03942  B03941_20200620        4  Mock\n",
       "87  B03942  B03961_20200622        6  Mock\n",
       "88  B03942  B03911_20200624        8  Mock"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entries where subject ID does not match filename (confirmed we should keep these)\n",
    "mask = (data.Subject != data['File Name'].str.split('_', n = 1, expand=True)[0])\n",
    "data.loc[mask,['Subject','File Name','StudyDay','Class']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove entries at baseline or after day 8 time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of subjects that had a StudyDays 2, 4, and 6\n",
    "subj_list = data.loc[data['StudyDay'].isin(['2','4','6']),'Subject']\n",
    "\n",
    "# Drop all other subjects and extra rows of other time points (for simplicity)\n",
    "ignore_days = ['BL','BL4','10','12','19','30']\n",
    "data.drop(data[(data['StudyDay'].isin(ignore_days)) | (~data.Subject.isin(subj_list))].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FALSE: I've got 99 problems, but rows with the same subj_id and StudyDay is not one\n"
     ]
    }
   ],
   "source": [
    "# Check for rows with the same subj_id and StudyDay\n",
    "ninetynine(len(data.loc[data.duplicated(subset=['Subject','StudyDay'])])>0,'rows with the same subj_id and StudyDay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate time points into separate columns\n",
    "data = data.set_index(['Subject','StudyDay']).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the change from pre-exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in var_cols:\n",
    "    # Collapse pre-exposure values (should have one per subject)\n",
    "    data.loc[:,(var,'pre')] = data.loc[:,(var,['-5','-6','-7'])].mean(axis = 1, skipna = True)\n",
    "\n",
    "    # Calculate the change from pre-exposure\n",
    "    data.loc[:,(var,'pre_delta')] = data.loc[:,(var,'pre')]-data.loc[:,(var,'pre')] #should be all 0\n",
    "    data.loc[:,(var,'2_delta')] = data.loc[:,(var,'2')]-data.loc[:,(var,'pre')]\n",
    "    data.loc[:,(var,'4_delta')] = data.loc[:,(var,'4')]-data.loc[:,(var,'pre')]\n",
    "    data.loc[:,(var,'6_delta')] = data.loc[:,(var,'6')]-data.loc[:,(var,'pre')]\n",
    "    data.loc[:,(var,'8_delta')] = data.loc[:,(var,'8')]-data.loc[:,(var,'pre')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"7\" halign=\"left\">Study</th>\n",
       "      <th colspan=\"3\" halign=\"left\">StudyDate</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Contrast-ngtdm</th>\n",
       "      <th colspan=\"6\" halign=\"left\">Busyness-ngtdm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StudyDay</th>\n",
       "      <th>-5</th>\n",
       "      <th>-6</th>\n",
       "      <th>-7</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>-5</th>\n",
       "      <th>-6</th>\n",
       "      <th>-7</th>\n",
       "      <th>...</th>\n",
       "      <th>2_delta</th>\n",
       "      <th>4_delta</th>\n",
       "      <th>6_delta</th>\n",
       "      <th>8_delta</th>\n",
       "      <th>pre</th>\n",
       "      <th>pre_delta</th>\n",
       "      <th>2_delta</th>\n",
       "      <th>4_delta</th>\n",
       "      <th>6_delta</th>\n",
       "      <th>8_delta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B03757</th>\n",
       "      <td>NaN</td>\n",
       "      <td>64-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64-01</td>\n",
       "      <td>64-01</td>\n",
       "      <td>64-01</td>\n",
       "      <td>64-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020/03/16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012990</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>-0.004608</td>\n",
       "      <td>1200.810742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-965.677485</td>\n",
       "      <td>-857.330332</td>\n",
       "      <td>-857.721661</td>\n",
       "      <td>-771.388894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03781</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64-02</td>\n",
       "      <td>64-02</td>\n",
       "      <td>64-02</td>\n",
       "      <td>64-02</td>\n",
       "      <td>64-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020/06/10</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013450</td>\n",
       "      <td>-0.012341</td>\n",
       "      <td>-0.014196</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>759.886160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-334.435885</td>\n",
       "      <td>-254.084988</td>\n",
       "      <td>-110.322327</td>\n",
       "      <td>21.745617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03819</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64-02</td>\n",
       "      <td>64-02</td>\n",
       "      <td>64-02</td>\n",
       "      <td>64-02</td>\n",
       "      <td>64-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020/06/10</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004805</td>\n",
       "      <td>-0.021873</td>\n",
       "      <td>-0.011045</td>\n",
       "      <td>-0.013539</td>\n",
       "      <td>898.182254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-454.862459</td>\n",
       "      <td>-761.628902</td>\n",
       "      <td>-561.964909</td>\n",
       "      <td>-417.221327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03828</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64-02</td>\n",
       "      <td>64-02</td>\n",
       "      <td>64-02</td>\n",
       "      <td>64-02</td>\n",
       "      <td>64-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020/06/09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>-0.000789</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>803.870337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.062826</td>\n",
       "      <td>3.483671</td>\n",
       "      <td>279.038216</td>\n",
       "      <td>313.243609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B03843</th>\n",
       "      <td>64-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64-01</td>\n",
       "      <td>64-01</td>\n",
       "      <td>64-01</td>\n",
       "      <td>64-01</td>\n",
       "      <td>2020/03/16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004060</td>\n",
       "      <td>-0.004307</td>\n",
       "      <td>-0.003359</td>\n",
       "      <td>-0.001183</td>\n",
       "      <td>1727.274784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-241.882499</td>\n",
       "      <td>-115.547354</td>\n",
       "      <td>53.090560</td>\n",
       "      <td>-222.430157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1471 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Study                                             StudyDate  \\\n",
       "StudyDay     -5     -6     -7      2      4      6      8          -5   \n",
       "Subject                                                                 \n",
       "B03757      NaN  64-01    NaN  64-01  64-01  64-01  64-01         NaN   \n",
       "B03781      NaN    NaN  64-02  64-02  64-02  64-02  64-02         NaN   \n",
       "B03819      NaN    NaN  64-02  64-02  64-02  64-02  64-02         NaN   \n",
       "B03828      NaN    NaN  64-02  64-02  64-02  64-02  64-02         NaN   \n",
       "B03843    64-01    NaN    NaN  64-01  64-01  64-01  64-01  2020/03/16   \n",
       "\n",
       "                                  ... Contrast-ngtdm                      \\\n",
       "StudyDay          -6          -7  ...        2_delta   4_delta   6_delta   \n",
       "Subject                           ...                                      \n",
       "B03757    2020/03/16         NaN  ...      -0.012990  0.003805  0.000367   \n",
       "B03781           NaN  2020/06/10  ...      -0.013450 -0.012341 -0.014196   \n",
       "B03819           NaN  2020/06/10  ...      -0.004805 -0.021873 -0.011045   \n",
       "B03828           NaN  2020/06/09  ...       0.006496 -0.000789  0.002532   \n",
       "B03843           NaN         NaN  ...      -0.004060 -0.004307 -0.003359   \n",
       "\n",
       "                   Busyness-ngtdm                                    \\\n",
       "StudyDay   8_delta            pre pre_delta     2_delta     4_delta   \n",
       "Subject                                                               \n",
       "B03757   -0.004608    1200.810742       0.0 -965.677485 -857.330332   \n",
       "B03781   -0.000580     759.886160       0.0 -334.435885 -254.084988   \n",
       "B03819   -0.013539     898.182254       0.0 -454.862459 -761.628902   \n",
       "B03828    0.002675     803.870337       0.0  185.062826    3.483671   \n",
       "B03843   -0.001183    1727.274784       0.0 -241.882499 -115.547354   \n",
       "\n",
       "                                  \n",
       "StudyDay     6_delta     8_delta  \n",
       "Subject                           \n",
       "B03757   -857.721661 -771.388894  \n",
       "B03781   -110.322327   21.745617  \n",
       "B03819   -561.964909 -417.221327  \n",
       "B03828    279.038216  313.243609  \n",
       "B03843     53.090560 -222.430157  \n",
       "\n",
       "[5 rows x 1471 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the class to the new columns from the original columns\n",
    "\n",
    "# stack and unstack so that missing columns fill in with null\n",
    "data = data.stack().unstack()\n",
    "\n",
    "time_points=['pre','2','4','6','8','pre_delta','2_delta','4_delta','6_delta','8_delta']\n",
    "delta_time=['pre_delta','2_delta','4_delta','6_delta','8_delta']\n",
    "# back-fill and foward-fill incase the column order changes\n",
    "data.loc[:,('Class',time_points)] = data.loc[:,('Class',time_points)].fillna(method='ffill',axis=1).fillna(method='bfill',axis=1)\n",
    "\n",
    "# Reformat for readability\n",
    "data = data.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment for different popular views of the data\n",
    "#data#.describe()\n",
    "#data.unstack()['Strength']\n",
    "\n",
    "#data.groupby(['StudyDay','Class']).describe()\n",
    "\n",
    "#data.loc[data['StudyDay'] == -6]\n",
    "#data.reset_index().loc[data['Subject'] == 'B03942',['Subject','StudyDay','Class']]\n",
    "#data.loc[(data.Class == 'Mock') & (data.StudyDay == '2')]\n",
    "#data.loc[data['Class'] == 'Infected',['Subject','Class']]\n",
    "#data.reset_index()\n",
    "#data.describe()\n",
    "#data.loc[(data.Class == 'Mock') & (data.StudyDay == '2'),'Subject']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save resulting tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full table (no error values)\n",
    "data.to_csv(os.path.join(PATH,'tables','data_radio.csv'))\n",
    "\n",
    "# Save simplified table (only delta timepoints)\n",
    "data = data.reset_index()\n",
    "data_deltaOnly = data.drop(data[data['StudyDay'].isin(['-5','-6','-7','2','4','6','8','pre','pre_delta'])].index)\n",
    "data_deltaOnly.set_index(['Subject','StudyDay']).to_csv(os.path.join(PATH,'tables','data_radio_delta.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude variables based on domain-specific feature screening criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_MCExclude=['SurfaceVolumeRatio-shape','Maximum2DDiameterSlice-shape'\n",
    ",'MaximumProbability-glcm','DifferenceEntropy-glcm'\n",
    ",'InverseVariance-glcm','SmallDependenceEmphasis-gldm'\n",
    ",'DependenceNonUniformityNormalized-gldm','LargeDependenceEmphasis-gldm'\n",
    ",'LargeDependenceLowGrayLevelEmphasis-gldm','DependenceVariance-gldm'\n",
    ",'SmallDependenceLowGrayLevelEmphasis-gldm'\n",
    ",'Minimum-firstorder'\n",
    ",'RunVariance-glrlm','LongRunEmphasis-glrlm'\n",
    ",'ShortRunEmphasis-glrlm','RunPercentage-glrlm'\n",
    ",'LongRunLowGrayLevelEmphasis-glrlm','RunLengthNonUniformityNormalized-glrlm'\n",
    ",'ZonePercentage-glszm','LowGrayLevelZoneEmphasis-glszm'\n",
    ",'SmallAreaLowGrayLevelEmphasis-glszm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that listed variables are all in the dataset\n",
    "for var in var_MCExclude:\n",
    "    if not var in data.columns.tolist():\n",
    "        print('Not in dataset:',var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of subset of variables after domain-specific feature screening\n",
    "var_cols = [ var for var in var_cols if not var in var_MCExclude]\n",
    "\n",
    "# Write to status message file, change this anytime this part of the analysis changes\n",
    "status='radioExcl_MC;'\n",
    "with open(os.path.join('..','config','analysis_status','u_radio.txt'),'w') as out_file:\n",
    "    out_file.write(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the objects:\n",
    "with open('../config/lists_radio.pkl', 'wb') as f:\n",
    "    pickle.dump([id_cols,var_cols,time_points,delta_time], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) VoxelVolume-shape\n",
      "2) Maximum3DDiameter-shape\n",
      "3) Compactness2-shape\n",
      "4) MeshVolume-shape\n",
      "5) MajorAxisLength-shape\n",
      "6) Sphericity-shape\n",
      "7) LeastAxisLength-shape\n",
      "8) Elongation-shape\n",
      "9) Compactness1-shape\n",
      "10) Flatness-shape\n",
      "11) SurfaceArea-shape\n",
      "12) MinorAxisLength-shape\n",
      "13) Maximum2DDiameterColumn-shape\n",
      "14) SphericalDisproportion-shape\n",
      "15) Maximum2DDiameterRow-shape\n",
      "16) JointAverage-glcm\n",
      "17) Autocorrelation-glcm\n",
      "18) JointEntropy-glcm\n",
      "19) ClusterShade-glcm\n",
      "20) Idmn-glcm\n",
      "21) JointEnergy-glcm\n",
      "22) Contrast-glcm\n",
      "23) DifferenceVariance-glcm\n",
      "24) Idn-glcm\n",
      "25) Idm-glcm\n",
      "26) Correlation-glcm\n",
      "27) SumAverage-glcm\n",
      "28) SumEntropy-glcm\n",
      "29) MCC-glcm\n",
      "30) SumSquares-glcm\n",
      "31) ClusterProminence-glcm\n",
      "32) Imc2-glcm\n",
      "33) Imc1-glcm\n",
      "34) DifferenceAverage-glcm\n",
      "35) Id-glcm\n",
      "36) ClusterTendency-glcm\n",
      "37) GrayLevelVariance-gldm\n",
      "38) HighGrayLevelEmphasis-gldm\n",
      "39) DependenceEntropy-gldm\n",
      "40) DependenceNonUniformity-gldm\n",
      "41) GrayLevelNonUniformity-gldm\n",
      "42) SmallDependenceHighGrayLevelEmphasis-gldm\n",
      "43) LargeDependenceHighGrayLevelEmphasis-gldm\n",
      "44) LowGrayLevelEmphasis-gldm\n",
      "45) InterquartileRange-firstorder\n",
      "46) Skewness-firstorder\n",
      "47) Uniformity-firstorder\n",
      "48) Median-firstorder\n",
      "49) Energy-firstorder\n",
      "50) RobustMeanAbsoluteDeviation-firstorder\n",
      "51) MeanAbsoluteDeviation-firstorder\n",
      "52) StandardDeviation-firstorder\n",
      "53) TotalEnergy-firstorder\n",
      "54) RootMeanSquared-firstorder\n",
      "55) 90Percentile-firstorder\n",
      "56) Entropy-firstorder\n",
      "57) Range-firstorder\n",
      "58) Variance-firstorder\n",
      "59) 10Percentile-firstorder\n",
      "60) Kurtosis-firstorder\n",
      "61) Maximum-firstorder\n",
      "62) Mean-firstorder\n",
      "63) ShortRunLowGrayLevelEmphasis-glrlm\n",
      "64) GrayLevelVariance-glrlm\n",
      "65) LowGrayLevelRunEmphasis-glrlm\n",
      "66) GrayLevelNonUniformityNormalized-glrlm\n",
      "67) GrayLevelNonUniformity-glrlm\n",
      "68) ShortRunHighGrayLevelEmphasis-glrlm\n",
      "69) RunLengthNonUniformity-glrlm\n",
      "70) LongRunHighGrayLevelEmphasis-glrlm\n",
      "71) RunEntropy-glrlm\n",
      "72) HighGrayLevelRunEmphasis-glrlm\n",
      "73) GrayLevelVariance-glszm\n",
      "74) ZoneVariance-glszm\n",
      "75) GrayLevelNonUniformityNormalized-glszm\n",
      "76) SizeZoneNonUniformityNormalized-glszm\n",
      "77) SizeZoneNonUniformity-glszm\n",
      "78) GrayLevelNonUniformity-glszm\n",
      "79) LargeAreaEmphasis-glszm\n",
      "80) SmallAreaHighGrayLevelEmphasis-glszm\n",
      "81) LargeAreaLowGrayLevelEmphasis-glszm\n",
      "82) LargeAreaHighGrayLevelEmphasis-glszm\n",
      "83) HighGrayLevelZoneEmphasis-glszm\n",
      "84) SmallAreaEmphasis-glszm\n",
      "85) ZoneEntropy-glszm\n",
      "86) Coarseness-ngtdm\n",
      "87) Complexity-ngtdm\n",
      "88) Strength-ngtdm\n",
      "89) Contrast-ngtdm\n",
      "90) Busyness-ngtdm\n"
     ]
    }
   ],
   "source": [
    "# Print column names\n",
    "i=0\n",
    "for name in var_cols:\n",
    "    i += 1\n",
    "    print (str(i)+') '+str(name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
